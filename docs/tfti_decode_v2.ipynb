{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import collections\n",
    "\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor import problems\n",
    "from tensor2tensor.layers import common_layers\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import t2t_model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.utils import metrics\n",
    "\n",
    "sys.path.append(\"../tfti\")\n",
    "import tfti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "#         HELPER FNS         #\n",
    "##############################\n",
    "\n",
    "def get_init_op():\n",
    "    \"\"\"Returns an initialization op.\"\"\"\n",
    "    global_init_op = tf.global_variables_initializer()\n",
    "    local_init_op = tf.local_variables_initializer()\n",
    "    return tf.group(global_init_op, local_init_op)\n",
    "\n",
    "def get_session(is_interactive=True, **kwargs):\n",
    "    \"\"\"Returns a session.\"\"\"\n",
    "    config = tf.ConfigProto(\n",
    "        log_device_placement=True,\n",
    "        allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    if is_interactive:\n",
    "        return tf.InteractiveSession(config=config, **kwargs)\n",
    "    else:\n",
    "        return tf.Session(config=config, **kwargs)\n",
    "\n",
    "def restore_from_checkpoint(session, ckpt_dir=None):\n",
    "    \"\"\"Restores session from checkpoint.\"\"\"\n",
    "    if ckpt_dir is None:\n",
    "        tf.logging.warn(\"Value for argument ckpt_dir is `None`. \"\n",
    "                        \"Not restoring from checkpoint.\")\n",
    "    else:\n",
    "        saver = tf.train.Saver()\n",
    "        ckpt = tf.train.get_checkpoint_state(\n",
    "            ckpt_dir).model_checkpoint_path\n",
    "        saver.restore(session, ckpt)\n",
    "        \n",
    "def initialize_variables(session, ckpt_dir=None):\n",
    "    \"\"\"Initializes global and local variables.\"\"\"\n",
    "    init_op = get_init_op()\n",
    "    session.run(init_op)\n",
    "    restore_from_checkpoint(\n",
    "        session=sess,\n",
    "        ckpt_dir=ckpt_dir,\n",
    "    )\n",
    "    \n",
    "def prepare_pipeline(problem_name,\n",
    "                     model_name,\n",
    "                     hparams_set,\n",
    "                     hparams_overrides_str,\n",
    "                     data_dir=\"None\",\n",
    "                     mode=tf.estimator.ModeKeys.EVAL):\n",
    "    \"\"\"Returns a tuple: (problem, model, hparams).\"\"\"\n",
    "    problem = registry.problem(problem_name)\n",
    "    problem.get_feature_encoders()  # Creates encoders.\n",
    "    hparams = trainer_lib.create_hparams(\n",
    "        hparams_set, hparams_overrides_str, data_dir, problem_name)\n",
    "    model = registry.model(model_name)(hparams, mode)\n",
    "    return problem, model, hparams\n",
    "\n",
    "def get_latents_and_metrics_weights(problem, targets, keep_mask):\n",
    "    \"\"\"Creates latents and weights.\"\"\"\n",
    "    metrics_mask = tf.to_float(tf.logical_not(keep_mask))\n",
    "    float_keep_mask = tf.to_float(keep_mask)\n",
    "    latents = tf.to_int32(\n",
    "        float_keep_mask * tf.to_float(targets)\n",
    "        + (1.0 - float_keep_mask) * problem.unk_id)\n",
    "    return latents, metrics_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main body call\n",
    "\n",
    "* Redefine the `get_raw_data_generator` to yield raw inputs.\n",
    "* Also define `keep_mask` for deterministic masking/imputations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsetting shared_embedding_and_softmax_weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:10,332] Unsetting shared_embedding_and_softmax_weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:10,335] Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:10,337] Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:10,339] Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:10,340] Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:10,343] Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:10,345] Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Marks for CellType GM12878: [(204, 'GM12878|ATF2|None'), (205, 'GM12878|ATF3|None'), (207, 'GM12878|BCL11A|None'), (410, 'GM12878|BRCA1|None'), (210, 'GM12878|CEBPB|None'), (412, 'GM12878|CHD1|None'), (413, 'GM12878|CHD2|None'), (127, 'GM12878|CTCF|None'), (53, 'GM12878|DNase|None'), (128, 'GM12878|EZH2|None'), (212, 'GM12878|Egr-1|None'), (216, 'GM12878|GABP|None'), (420, 'GM12878|JunD|None'), (421, 'GM12878|Max|None'), (423, 'GM12878|Mxi1|None'), (223, 'GM12878|NRSF|None'), (428, 'GM12878|Nrf1|None'), (229, 'GM12878|Pol2-4H8|None'), (230, 'GM12878|Pol2|None'), (436, 'GM12878|RFX5|None'), (235, 'GM12878|RXRA|None'), (233, 'GM12878|Rad21|None'), (437, 'GM12878|SIN3A|None'), (236, 'GM12878|SIX5|None'), (237, 'GM12878|SP1|None'), (238, 'GM12878|SRF|None'), (240, 'GM12878|TAF1|None'), (442, 'GM12878|TBP|None'), (241, 'GM12878|TCF12|None'), (243, 'GM12878|USF-1|None'), (444, 'GM12878|USF2|None'), (244, 'GM12878|YY1|None'), (447, 'GM12878|Znf143|None'), (725, 'GM12878|c-Myc|None'), (224, 'GM12878|p300|None')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:10,352] Marks for CellType GM12878: [(204, 'GM12878|ATF2|None'), (205, 'GM12878|ATF3|None'), (207, 'GM12878|BCL11A|None'), (410, 'GM12878|BRCA1|None'), (210, 'GM12878|CEBPB|None'), (412, 'GM12878|CHD1|None'), (413, 'GM12878|CHD2|None'), (127, 'GM12878|CTCF|None'), (53, 'GM12878|DNase|None'), (128, 'GM12878|EZH2|None'), (212, 'GM12878|Egr-1|None'), (216, 'GM12878|GABP|None'), (420, 'GM12878|JunD|None'), (421, 'GM12878|Max|None'), (423, 'GM12878|Mxi1|None'), (223, 'GM12878|NRSF|None'), (428, 'GM12878|Nrf1|None'), (229, 'GM12878|Pol2-4H8|None'), (230, 'GM12878|Pol2|None'), (436, 'GM12878|RFX5|None'), (235, 'GM12878|RXRA|None'), (233, 'GM12878|Rad21|None'), (437, 'GM12878|SIN3A|None'), (236, 'GM12878|SIX5|None'), (237, 'GM12878|SP1|None'), (238, 'GM12878|SRF|None'), (240, 'GM12878|TAF1|None'), (442, 'GM12878|TBP|None'), (241, 'GM12878|TCF12|None'), (243, 'GM12878|USF-1|None'), (444, 'GM12878|USF2|None'), (244, 'GM12878|YY1|None'), (447, 'GM12878|Znf143|None'), (725, 'GM12878|c-Myc|None'), (224, 'GM12878|p300|None')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Marks for CellType GM12878: [(204, 'GM12878|ATF2|None'), (205, 'GM12878|ATF3|None'), (207, 'GM12878|BCL11A|None'), (410, 'GM12878|BRCA1|None'), (210, 'GM12878|CEBPB|None'), (412, 'GM12878|CHD1|None'), (413, 'GM12878|CHD2|None'), (127, 'GM12878|CTCF|None'), (53, 'GM12878|DNase|None'), (128, 'GM12878|EZH2|None'), (212, 'GM12878|Egr-1|None'), (216, 'GM12878|GABP|None'), (420, 'GM12878|JunD|None'), (421, 'GM12878|Max|None'), (423, 'GM12878|Mxi1|None'), (223, 'GM12878|NRSF|None'), (428, 'GM12878|Nrf1|None'), (229, 'GM12878|Pol2-4H8|None'), (230, 'GM12878|Pol2|None'), (436, 'GM12878|RFX5|None'), (235, 'GM12878|RXRA|None'), (233, 'GM12878|Rad21|None'), (437, 'GM12878|SIN3A|None'), (236, 'GM12878|SIX5|None'), (237, 'GM12878|SP1|None'), (238, 'GM12878|SRF|None'), (240, 'GM12878|TAF1|None'), (442, 'GM12878|TBP|None'), (241, 'GM12878|TCF12|None'), (243, 'GM12878|USF-1|None'), (444, 'GM12878|USF2|None'), (244, 'GM12878|YY1|None'), (447, 'GM12878|Znf143|None'), (725, 'GM12878|c-Myc|None'), (224, 'GM12878|p300|None')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:10,359] Marks for CellType GM12878: [(204, 'GM12878|ATF2|None'), (205, 'GM12878|ATF3|None'), (207, 'GM12878|BCL11A|None'), (410, 'GM12878|BRCA1|None'), (210, 'GM12878|CEBPB|None'), (412, 'GM12878|CHD1|None'), (413, 'GM12878|CHD2|None'), (127, 'GM12878|CTCF|None'), (53, 'GM12878|DNase|None'), (128, 'GM12878|EZH2|None'), (212, 'GM12878|Egr-1|None'), (216, 'GM12878|GABP|None'), (420, 'GM12878|JunD|None'), (421, 'GM12878|Max|None'), (423, 'GM12878|Mxi1|None'), (223, 'GM12878|NRSF|None'), (428, 'GM12878|Nrf1|None'), (229, 'GM12878|Pol2-4H8|None'), (230, 'GM12878|Pol2|None'), (436, 'GM12878|RFX5|None'), (235, 'GM12878|RXRA|None'), (233, 'GM12878|Rad21|None'), (437, 'GM12878|SIN3A|None'), (236, 'GM12878|SIX5|None'), (237, 'GM12878|SP1|None'), (238, 'GM12878|SRF|None'), (240, 'GM12878|TAF1|None'), (442, 'GM12878|TBP|None'), (241, 'GM12878|TCF12|None'), (243, 'GM12878|USF-1|None'), (444, 'GM12878|USF2|None'), (244, 'GM12878|YY1|None'), (447, 'GM12878|Znf143|None'), (725, 'GM12878|c-Myc|None'), (224, 'GM12878|p300|None')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:10,442] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_782_8.bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:10,529] Transforming feature 'inputs' with symbol_modality_782_8.bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'latents' with binary_imputation_class_label_modality_8.bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:10,749] Transforming feature 'latents' with binary_imputation_class_label_modality_8.bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming 'targets' with binary_class_label_modality_8.targets_bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:11,390] Transforming 'targets' with binary_class_label_modality_8.targets_bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model body\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:11,457] Building model body\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming body output with binary_class_label_modality_8.top\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:14,771] Transforming body output with binary_class_label_modality_8.top\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value for argument ckpt_dir is `None`. Not restoring from checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 19:27:20,783] Value for argument ckpt_dir is `None`. Not restoring from checkpoint.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUROC for this latent mask is: 0.5089658498764038\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#         MAIN BODY          #\n",
    "##############################\n",
    "\n",
    "# Parameters\n",
    "problem_name=\"genomics_binding_deepsea_gm12878\"\n",
    "model_name=\"tfti_transformer\"\n",
    "hparams_set=\"tfti_transformer_debug\"\n",
    "hparams_overrides_str=\"\"\n",
    "ckpt_dir=None  # No checkpoint.\n",
    "batch_size=2  # For batch parallelism.\n",
    "keep_mask = np.random.choice(2, preprocessed_num_binary_predictions).astype(bool)  # Deterministic mask.\n",
    "\n",
    "def get_raw_data_generator():\n",
    "    \"\"\"Yields raw inputs and targets.\n",
    "    \n",
    "    Yields:\n",
    "        Tuples containing:\n",
    "            inputs: NACTG strings of length 1000.\n",
    "            targets: An binary label array of length 919.\n",
    "    \"\"\"\n",
    "    # TODO: redefine this to read from a file.\n",
    "    \n",
    "    ##############################\n",
    "    #      YOUR CODE HERE!       #\n",
    "    ##############################\n",
    "    \n",
    "    for _ in range(100):\n",
    "        raw_inputs = \"\".join(np.random.choice(list(\"NACTG\"), problem.input_sequence_length))\n",
    "        raw_targets = (np.random.random(problem.num_binary_predictions) < 0.5).astype(int)\n",
    "        yield raw_inputs, raw_targets\n",
    "\n",
    "\n",
    "# Reset graph for consistency.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Construct pipeline.\n",
    "problem, model, hparams = prepare_pipeline(\n",
    "    problem_name, model_name, hparams_set, hparams_overrides_str)\n",
    "\n",
    "# Shapes for preprocessed inputs/targets/latents.\n",
    "preprocessed_input_sequence_length = int(np.ceil(problem.input_sequence_length / problem.chunk_size))\n",
    "preprocessed_num_binary_predictions = len(problem.targets_gather_indices())\n",
    "targets_gather_indices = problem.targets_gather_indices()\n",
    "\n",
    "def get_processed_data_generator_fn(raw_data_generator, keep_mask):\n",
    "    # Reshape to rank 3 arrays/tensors.\n",
    "    keep_mask = keep_mask.reshape([-1, 1, 1])\n",
    "    def get_processed_data_generator():\n",
    "        for raw_inputs, raw_targets in raw_data_generator:\n",
    "            preprocessed_inputs = np.array(problem._encoders[\"inputs\"].encode(raw_inputs), dtype=np.int64)\n",
    "            preprocessed_targets = raw_targets[targets_gather_indices]\n",
    "            # Reshape to rank 3 arrays/tensors.\n",
    "            preprocessed_inputs = preprocessed_inputs.reshape([-1, 1, 1])\n",
    "            preprocessed_targets = preprocessed_targets.reshape([-1, 1, 1])\n",
    "            yield preprocessed_inputs, preprocessed_targets, keep_mask\n",
    "    return get_processed_data_generator\n",
    "\n",
    "# Create dataset from generator.\n",
    "raw_data_generator = get_raw_data_generator()\n",
    "processed_data_generator_fn = get_processed_data_generator_fn(raw_data_generator, keep_mask)\n",
    "ds = tf.data.Dataset.from_generator(\n",
    "    processed_data_generator_fn,\n",
    "    output_types=(tf.int64, tf.int64, tf.bool),\n",
    "    output_shapes=(\n",
    "        [preprocessed_input_sequence_length, 1, 1],\n",
    "        [preprocessed_num_binary_predictions, 1, 1],\n",
    "        [preprocessed_num_binary_predictions, 1, 1],\n",
    "    )\n",
    ")\n",
    "\n",
    "ds = ds.repeat(1)  # Single evaluation epoch.\n",
    "ds = ds.batch(batch_size)\n",
    "\n",
    "# Create one-shot-iterator.\n",
    "next_item = ds.make_one_shot_iterator().get_next()\n",
    "preprocessed_inputs, preprocessed_targets, latents_keep_mask = next_item\n",
    "\n",
    "# Create the latents from the targets and mask.\n",
    "latents, metrics_mask = get_latents_and_metrics_weights(problem, preprocessed_targets, latents_keep_mask)\n",
    "\n",
    "# Pass preprocessed features through model.\n",
    "preprocessed_features = {\n",
    "    \"inputs\": preprocessed_inputs,\n",
    "    \"targets\": preprocessed_targets,\n",
    "    \"latents\": latents,\n",
    "    \"metrics_mask\": metrics_mask,\n",
    "}\n",
    "logits, losses = model(preprocessed_features)\n",
    "labels = preprocessed_features[\"targets\"]\n",
    "\n",
    "# Evaluation metrics we want to use.\n",
    "set_auroc, _ = tfti.set_auroc(logits, labels, preprocessed_features)\n",
    "set_auprc, _ = tfti.set_auprc(logits, labels, preprocessed_features)\n",
    "average_auroc, _ = tfti.average_auroc(logits, labels, preprocessed_features)\n",
    "average_auprc, _ = tfti.average_auprc(logits, labels, preprocessed_features)\n",
    "\n",
    "# Initialize weights - randomly or from checkpoint\n",
    "sess = get_session(is_interactive=False)\n",
    "initialize_variables(sess, ckpt_dir)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # average_auroc updates a numerator & denominator\n",
    "        # and computes the average_auroc for the entire dataset.\n",
    "        final_average_auroc = sess.run(average_auroc)\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print(f\"Average AUROC for this latent mask is: {final_average_auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
