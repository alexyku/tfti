{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/akmorrow/anaconda2/envs/python36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/akmorrow/anaconda2/envs/python36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import collections\n",
    "\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor import problems\n",
    "from tensor2tensor.layers import common_layers\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import t2t_model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.utils import metrics\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USER CONFIGURES ###\n",
    "data_dir = \"/data/akmorrow/tfti/t2t_data\"\n",
    "train_dir = \"/data/akmorrow/tfti/t2t_train\"\n",
    "validation_file = \"/data/akmorrow/tfti/data/deepseavalidation.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Overriding hparams in tfti_transformer_base with batch_size=64,num_encoder_layers=4,num_decoder_layers=2,learning_rate_constant=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,227] Overriding hparams in tfti_transformer_base with batch_size=64,num_encoder_layers=4,num_decoder_layers=2,learning_rate_constant=0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsetting shared_embedding_and_softmax_weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,231] Unsetting shared_embedding_and_softmax_weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,233] Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,236] Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,239] Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,241] Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,242] Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,244] Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tfti.TftiTransformer object at 0x7f0342c77f98>\n",
      "INFO:tensorflow:TFs for CellType H1-hESC: ['CTCF', 'Pol2-4H8', 'JunD', 'SRF', 'CHD2', 'GABP', 'YY1', 'EZH2', 'Nrf1', 'USF-1', 'Znf143', 'TBP', 'SIX5', 'NRSF', 'p300', 'USF2', 'BCL11A', 'SIN3A', 'CHD1', 'Egr-1', 'TAF1', 'CEBPB', 'Mxi1', 'RXRA', 'c-Myc', 'ATF2', 'ATF3', 'Rad21', 'Pol2', 'TCF12', 'BRCA1', 'SP1', 'RFX5', 'Max']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,277] TFs for CellType H1-hESC: ['CTCF', 'Pol2-4H8', 'JunD', 'SRF', 'CHD2', 'GABP', 'YY1', 'EZH2', 'Nrf1', 'USF-1', 'Znf143', 'TBP', 'SIX5', 'NRSF', 'p300', 'USF2', 'BCL11A', 'SIN3A', 'CHD1', 'Egr-1', 'TAF1', 'CEBPB', 'Mxi1', 'RXRA', 'c-Myc', 'ATF2', 'ATF3', 'Rad21', 'Pol2', 'TCF12', 'BRCA1', 'SP1', 'RFX5', 'Max']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:[259, 260, 261, 467, 468, 129, 470, 130, 131, 263, 265, 267, 477, 478, 269, 479, 271, 272, 481, 275, 274, 482, 277, 278, 281, 282, 484, 284, 286, 485, 287, 486, 472, 270]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,278] [259, 260, 261, 467, 468, 129, 470, 130, 131, 263, 265, 267, 477, 478, 269, 479, 271, 272, 481, 275, 274, 482, 277, 278, 281, 282, 484, 284, 286, 485, 287, 486, 472, 270]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,293] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_782_512.bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,322] Transforming feature 'inputs' with symbol_modality_782_512.bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'latents' with binary_imputation_class_label_modality_512.bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,419] Transforming feature 'latents' with binary_imputation_class_label_modality_512.bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming 'targets' with binary_class_label_modality_512.targets_bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,446] Transforming 'targets' with binary_class_label_modality_512.targets_bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model body\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:21,463] Building model body\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming body output with binary_class_label_modality_512.top\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-24 11:55:22,933] Transforming body output with binary_class_label_modality_512.top\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.core.protobuf.config_pb2.ConfigProto'>\n",
      "<class 'tensorflow.core.protobuf.config_pb2.RunOptions'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f0328984f28>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/akmorrow/anaconda2/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 710, in __del__\n",
      "    if self._session is not None:\n",
      "AttributeError: 'InteractiveSession' object has no attribute '_session'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'options'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-64b51d3de095>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_gpu_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Initialize AUC running average stuff.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'options'"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"../tfti\")\n",
    "import tfti\n",
    "\n",
    "# Reset graph for conistency.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Prepare model.\n",
    "problem_name = \"genomics_binding_deepsea_gm12878\"\n",
    "model_name = \"tfti_transformer\"\n",
    "hparams_set = \"tfti_transformer_base\"\n",
    "hparams_overrides_str = \"batch_size=64,num_encoder_layers=4,num_decoder_layers=2,learning_rate_constant=0.2\"\n",
    "\n",
    "data_dir = os.path.expanduser(data_dir)\n",
    "output_dir = os.path.expanduser(train_dir + f\"/{problem_name}/{model_name}-{hparams_overrides_str}\")\n",
    "# output_dir = os.path.expanduser(\"/data/akmorrow/tfti/t2t_train/genomics_binding_deepsea_gm12878/tfti_transformer-params_tfti_transformer_debug\")\n",
    "\n",
    "# Prepare model.\n",
    "hparams = trainer_lib.create_hparams(hparams_set, hparams_overrides_str, data_dir, problem_name)\n",
    "problem = registry.problem(problem_name)\n",
    "encoders = problem.get_feature_encoders(data_dir)\n",
    "\n",
    "# Prepare the model and the graph when model runs on features.\n",
    "model = registry.model(model_name)(hparams, tf.estimator.ModeKeys.EVAL)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Prepare features for feeding into the model.\n",
    "inputs_ph = tf.placeholder(dtype=tf.string, shape=[ ])\n",
    "targets_ph = tf.placeholder(dtype=tf.int64, shape=[problem.num_binary_predictions])\n",
    "features = {\"inputs\": inputs_ph, \"targets\": targets_ph}\n",
    "features = problem.preprocess_dev_example(features, tf.estimator.ModeKeys.EVAL, hparams)\n",
    "\n",
    "# Introduce a dummy batch dimension.\n",
    "for key in features.keys():\n",
    "    features[key] = tf.expand_dims(features[key], 0)\n",
    "\n",
    "logits, losses = model(features)\n",
    "predictions = tf.nn.sigmoid(logits)\n",
    "labels = features[\"targets\"]\n",
    "\n",
    "# Evaluation metrics we want to use.\n",
    "set_auroc, _ = tfti.set_auroc(logits, labels, features)\n",
    "set_auprc, _ = tfti.set_auprc(logits, labels, features)\n",
    "average_auroc, _ = tfti.average_auroc(logits, labels, features)\n",
    "average_auprc, _ = tfti.average_auprc(logits, labels, features)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def make_gpu_config():\n",
    "    config = tf.ConfigProto(\n",
    "        log_device_placement=False,\n",
    "        allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return config\n",
    "\n",
    "print(type(make_gpu_config()))\n",
    "\n",
    "# config = tf.ConfigProto(\n",
    "#     log_device_placement=False,\n",
    "#     allow_soft_placement=True),\n",
    "#     tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "# sess.run(op, feed_dict=fdict, options=run_options)\n",
    "print(type(run_options))\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession(config=make_gpu_config(),options=run_options)\n",
    "\n",
    "# Initialize AUC running average stuff.\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "sess.run(init_op)\n",
    "\n",
    "# Load weights from checkpoint.\n",
    "ckpts = tf.train.get_checkpoint_state(output_dir)\n",
    "print(ckpts)\n",
    "ckpt = ckpts.model_checkpoint_path\n",
    "saver.restore(sess, ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-26-a39ffd653252>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-a39ffd653252>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    tf.RunOptions(report_tensor_allocations_upon_oom = True)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(\n",
    "    log_device_placement=False,\n",
    "    allow_soft_placement=True),\n",
    "    tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "sess.run(op, feed_dict=fdict, options=run_options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in test data\n",
    "import pandas as pd\n",
    "validation_data=pd.read_csv(validation_file, sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse prediction file and run graph\n",
    "\n",
    "predictions_and_labels = []\n",
    "\n",
    "for i in range(len(validation_data)):\n",
    "    inputs = validation_data[0][i]\n",
    "    targets = np.array(list(map(int, validation_data[1][i].split(','))))\n",
    "    \n",
    "    fetch = (predictions, labels)\n",
    "    fetch_numpy = sess.run(fetch, feed_dict={\n",
    "        inputs_ph: inputs,\n",
    "        targets_ph: targets\n",
    "    })\n",
    "    \n",
    "    predictions_and_labels.append(fetch_numpy)\n",
    "    \n",
    "predictions_and_labels = [(x.squeeze(), y.squeeze())\n",
    "                          for (x, y) in predictions_and_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_numpy = np.array(predictions_and_labels)[:, 0, :]\n",
    "labels_numpy = np.array(predictions_and_labels)[:, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the 34 TFs we are evaluating on\n",
    "tfs = sorted(['SP1', 'Pol2-4H8', 'USF2', 'NRSF', 'RFX5', 'c-Myc', 'RXRA', 'EZH2', 'TBP', 'CHD1', 'Egr-1', 'SIN3A', 'GABP', 'CEBPB', 'Nrf1', 'p300', 'CTCF', 'ATF3', 'ATF2', 'Pol2', 'BCL11A', 'BRCA1', 'TCF12', 'SIX5', 'JunD', 'Rad21', 'YY1', 'USF-1', 'Max', 'TAF1', 'CHD2', 'Mxi1', 'SRF', 'Znf143'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make ROC plots on all TFs\n",
    "plt.figure()\n",
    "\n",
    "lw = 2\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "\n",
    "for i in range(len(tfs)):\n",
    "    tf_ = tfs[i]\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, _ = roc_curve(labels_numpy[:,i], predictions_numpy[:,i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, lw, label='%s (%0.2f)' % (tf_, roc_auc))\n",
    "    \n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
