{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- fix overlapping_tfs function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Dependency imports\n",
    "\n",
    "from tensor2tensor.bin import t2t_trainer\n",
    "from tensor2tensor.data_generators import text_encoder\n",
    "from tensor2tensor.utils import decoding\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import usr_dir\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# for metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "sys.path.append(\"../tfti\")\n",
    "import tfti\n",
    "import tfti_infer\n",
    "\n",
    "\n",
    "\n",
    "from itertools import combinations\n",
    "import math\n",
    "import bisect\n",
    "import sys\n",
    "from skpp import ProjectionPursuitRegressor\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "sys.path.append(\"../tfti\")\n",
    "from tfti_batched_inference import *\n",
    "\n",
    "sys.path.append(\"../shapley\")\n",
    "import shapley\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing MSA\n",
    "\n",
    "First, run the real Shapley values. This is an example taken from the Wiki https://en.wikipedia.org/wiki/Shapley_value, demonstrating the contributions of workers (w) and bosses (o), where the value function is mp if the boss o is in the set, and 0 otherwise, where m = the number of workers in the set S and p is the profit from each worker.\n",
    "\n",
    "\n",
    "First, we compute the full Shapley values.\n",
    "\n",
    "## Full Shapley Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapley values for all workers are [0.5, 0.5, 0.5, 0.5, 2.0]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(shapley)\n",
    "p = 1 # contribution of each worker\n",
    "\n",
    "# 4 workers and 1 owner\n",
    "players = np.array(['w','w','w','w','o'])\n",
    "k = (players == 'w').sum()\n",
    "\n",
    "def v(S):\n",
    "    if ('o' in S):\n",
    "        m = (S == 'w').sum()\n",
    "        return m * p\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "orderedList = list([i for i in range(len(players))])\n",
    "R_orderings = shapley.power_set(orderedList)    \n",
    "characteristic_function = list(map(lambda x: v(players[x]), R_orderings))\n",
    "\n",
    "# compute the actual Shapley value\n",
    "shapleys = shapley.compute_shapley_values(players, characteristic_function)\n",
    "print(\"Shapley values for all workers are %s\" % shapleys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the reuslts\n",
    "\n",
    "As you can see, all workers have a contribution of 0.5, and the boss ('o') has a contribution of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had to compute 32 instances of the value function \n",
      "[0.5, 0.5, 0.5, 0.5, 2.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Had to compute %i instances of the value function \" % (len(R_orderings)))\n",
    "print(shapleys)\n",
    "assert(shapleys[0] == p/2)\n",
    "assert(shapleys[4] == (k * p)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Predicted Shapley Values\n",
    "\n",
    "Next, we compute the Shapley values on predicted value functions using the MSA algorithm. The main idea is that we do not need to compute all 31 instances of the value function. Instead, we will only compute 20 instances and use these to predict the missing value functions. This is useful because in our case, the value function is prediction the model and we have many TFs to predict on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all possible orderings of the players\n",
    "orderedList = list([i for i in range(len(players))])\n",
    "R_orderings = list(enumerate(shapley.power_set(orderedList)))\n",
    "\n",
    "# choose random subset of R_orderings\n",
    "sample_size = 20\n",
    "R_sampled_orderings = random.sample(R_orderings, sample_size)\n",
    "characteristic_function = np.zeros(len(R_orderings))\n",
    "\n",
    "# compute the characteristic function for sampled orderings\n",
    "# in our case, this will be computed from evaluating our model, building a mask from the current ordering\n",
    "train_data = np.zeros((sample_size, len(players)))\n",
    "y = np.zeros(sample_size)\n",
    "\n",
    "for i, x in enumerate(R_sampled_orderings):\n",
    "    y[i] = v(players[x[1]])\n",
    "    for j in x[1]:\n",
    "        train_data[i,j] = 1\n",
    "    characteristic_function[x[0]] = y[i] \n",
    "    \n",
    "\n",
    "# build a matrix that is #random calcs by len(players)  and predict on v\n",
    "estimator = ProjectionPursuitRegressor()\n",
    "estimator.fit(train_data, y)\n",
    "\n",
    "# predict the missing v(s) \n",
    "missing_R_orderings = [x for x in R_orderings if x not in R_sampled_orderings]\n",
    "for x in missing_R_orderings:\n",
    "    prediction_vector = np.zeros(len(players))\n",
    "    for j in x[1]:\n",
    "        prediction_vector[j] = 1\n",
    "    characteristic_function[x[0]] = estimator.predict(np.matrix(prediction_vector))\n",
    "\n",
    "\n",
    "# compute the actual Shapley value\n",
    "shapleys = shapley.compute_shapley_values(players, characteristic_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had to compute 20 instances of the value function \n",
      "[0.4127064531292884, 0.40945359593800823, 0.4128494995656109, 0.36382321344992297, 1.866972059724756]\n"
     ]
    }
   ],
   "source": [
    "print(\"Had to compute %i instances of the value function \" % (len(R_sampled_orderings)))\n",
    "print(shapleys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsetting shared_embedding_and_softmax_weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,634] Unsetting shared_embedding_and_softmax_weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,636] Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,637] Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,639] Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,640] Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,642] Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,643] Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Generating latents with a `latent_keep_mask`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,663] Generating latents with a `latent_keep_mask`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Marks for CellType GM12878: [(204, 'GM12878|ATF2|None'), (205, 'GM12878|ATF3|None'), (207, 'GM12878|BCL11A|None'), (410, 'GM12878|BRCA1|None'), (210, 'GM12878|CEBPB|None'), (412, 'GM12878|CHD1|None'), (413, 'GM12878|CHD2|None'), (127, 'GM12878|CTCF|None'), (53, 'GM12878|DNase|None'), (128, 'GM12878|EZH2|None'), (212, 'GM12878|Egr-1|None'), (216, 'GM12878|GABP|None'), (420, 'GM12878|JunD|None'), (421, 'GM12878|Max|None'), (423, 'GM12878|Mxi1|None'), (223, 'GM12878|NRSF|None'), (428, 'GM12878|Nrf1|None'), (229, 'GM12878|Pol2-4H8|None'), (230, 'GM12878|Pol2|None'), (436, 'GM12878|RFX5|None'), (235, 'GM12878|RXRA|None'), (233, 'GM12878|Rad21|None'), (437, 'GM12878|SIN3A|None'), (236, 'GM12878|SIX5|None'), (237, 'GM12878|SP1|None'), (238, 'GM12878|SRF|None'), (240, 'GM12878|TAF1|None'), (442, 'GM12878|TBP|None'), (241, 'GM12878|TCF12|None'), (243, 'GM12878|USF-1|None'), (444, 'GM12878|USF2|None'), (244, 'GM12878|YY1|None'), (447, 'GM12878|Znf143|None'), (725, 'GM12878|c-Myc|None'), (224, 'GM12878|p300|None')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,685] Marks for CellType GM12878: [(204, 'GM12878|ATF2|None'), (205, 'GM12878|ATF3|None'), (207, 'GM12878|BCL11A|None'), (410, 'GM12878|BRCA1|None'), (210, 'GM12878|CEBPB|None'), (412, 'GM12878|CHD1|None'), (413, 'GM12878|CHD2|None'), (127, 'GM12878|CTCF|None'), (53, 'GM12878|DNase|None'), (128, 'GM12878|EZH2|None'), (212, 'GM12878|Egr-1|None'), (216, 'GM12878|GABP|None'), (420, 'GM12878|JunD|None'), (421, 'GM12878|Max|None'), (423, 'GM12878|Mxi1|None'), (223, 'GM12878|NRSF|None'), (428, 'GM12878|Nrf1|None'), (229, 'GM12878|Pol2-4H8|None'), (230, 'GM12878|Pol2|None'), (436, 'GM12878|RFX5|None'), (235, 'GM12878|RXRA|None'), (233, 'GM12878|Rad21|None'), (437, 'GM12878|SIN3A|None'), (236, 'GM12878|SIX5|None'), (237, 'GM12878|SP1|None'), (238, 'GM12878|SRF|None'), (240, 'GM12878|TAF1|None'), (442, 'GM12878|TBP|None'), (241, 'GM12878|TCF12|None'), (243, 'GM12878|USF-1|None'), (444, 'GM12878|USF2|None'), (244, 'GM12878|YY1|None'), (447, 'GM12878|Znf143|None'), (725, 'GM12878|c-Myc|None'), (224, 'GM12878|p300|None')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsetting shared_embedding_and_softmax_weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,698] Unsetting shared_embedding_and_softmax_weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,700] Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,702] Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,703] Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,704] Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,705] Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,707] Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Marks for CellType GM12878: [(204, 'GM12878|ATF2|None'), (205, 'GM12878|ATF3|None'), (207, 'GM12878|BCL11A|None'), (410, 'GM12878|BRCA1|None'), (210, 'GM12878|CEBPB|None'), (412, 'GM12878|CHD1|None'), (413, 'GM12878|CHD2|None'), (127, 'GM12878|CTCF|None'), (53, 'GM12878|DNase|None'), (128, 'GM12878|EZH2|None'), (212, 'GM12878|Egr-1|None'), (216, 'GM12878|GABP|None'), (420, 'GM12878|JunD|None'), (421, 'GM12878|Max|None'), (423, 'GM12878|Mxi1|None'), (223, 'GM12878|NRSF|None'), (428, 'GM12878|Nrf1|None'), (229, 'GM12878|Pol2-4H8|None'), (230, 'GM12878|Pol2|None'), (436, 'GM12878|RFX5|None'), (235, 'GM12878|RXRA|None'), (233, 'GM12878|Rad21|None'), (437, 'GM12878|SIN3A|None'), (236, 'GM12878|SIX5|None'), (237, 'GM12878|SP1|None'), (238, 'GM12878|SRF|None'), (240, 'GM12878|TAF1|None'), (442, 'GM12878|TBP|None'), (241, 'GM12878|TCF12|None'), (243, 'GM12878|USF-1|None'), (444, 'GM12878|USF2|None'), (244, 'GM12878|YY1|None'), (447, 'GM12878|Znf143|None'), (725, 'GM12878|c-Myc|None'), (224, 'GM12878|p300|None')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,722] Marks for CellType GM12878: [(204, 'GM12878|ATF2|None'), (205, 'GM12878|ATF3|None'), (207, 'GM12878|BCL11A|None'), (410, 'GM12878|BRCA1|None'), (210, 'GM12878|CEBPB|None'), (412, 'GM12878|CHD1|None'), (413, 'GM12878|CHD2|None'), (127, 'GM12878|CTCF|None'), (53, 'GM12878|DNase|None'), (128, 'GM12878|EZH2|None'), (212, 'GM12878|Egr-1|None'), (216, 'GM12878|GABP|None'), (420, 'GM12878|JunD|None'), (421, 'GM12878|Max|None'), (423, 'GM12878|Mxi1|None'), (223, 'GM12878|NRSF|None'), (428, 'GM12878|Nrf1|None'), (229, 'GM12878|Pol2-4H8|None'), (230, 'GM12878|Pol2|None'), (436, 'GM12878|RFX5|None'), (235, 'GM12878|RXRA|None'), (233, 'GM12878|Rad21|None'), (437, 'GM12878|SIN3A|None'), (236, 'GM12878|SIX5|None'), (237, 'GM12878|SP1|None'), (238, 'GM12878|SRF|None'), (240, 'GM12878|TAF1|None'), (442, 'GM12878|TBP|None'), (241, 'GM12878|TCF12|None'), (243, 'GM12878|USF-1|None'), (444, 'GM12878|USF2|None'), (244, 'GM12878|YY1|None'), (447, 'GM12878|Znf143|None'), (725, 'GM12878|c-Myc|None'), (224, 'GM12878|p300|None')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,728] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_782_512.bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:39,766] Transforming feature 'inputs' with symbol_modality_782_512.bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'latents' with binary_imputation_class_label_modality_512.bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:40,213] Transforming feature 'latents' with binary_imputation_class_label_modality_512.bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming 'targets' with binary_class_label_modality_512.targets_bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:40,246] Transforming 'targets' with binary_class_label_modality_512.targets_bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model body\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:40,268] Building model body\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming body output with binary_class_label_modality_512.top\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:46,196] Transforming body output with binary_class_label_modality_512.top\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /data/akmorrow/tfti/t2t_train/6-64-25/model.ckpt-210001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:47,358] Restoring parameters from /data/akmorrow/tfti/t2t_train/6-64-25/model.ckpt-210001\n"
     ]
    }
   ],
   "source": [
    "config = get_config(\n",
    "    problem=\"genomics_binding_deepsea_gm12878\",\n",
    "    model=\"tfti_transformer\",\n",
    "    hparams_set=\"tfti_transformer_base\",\n",
    "    hparams=\"\",\n",
    "    checkpoint_path=\"/data/akmorrow/tfti/t2t_train/6-64-25/model.ckpt-210001\",\n",
    "\n",
    ")\n",
    "\n",
    "preprocess_batch_fn = get_preprocess_batch_fn(config)\n",
    "inference_fn = get_inference_fn(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Generator Data for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=1\n",
    "\n",
    "problem_str=\"genomics_binding_deepsea_gm12878\"\n",
    "model_str=\"tfti_transformer\"\n",
    "hparams_set_str=\"tfti_transformer_base\"\n",
    "hparams_str=\"\"\n",
    "checkpoint_path=\"/data/akmorrow/tfti/t2t_train/6-64-25/model.ckpt-210001\"\n",
    "\n",
    "# infer_fn = tfti_infer.get_infer_fn(\n",
    "#     problem=\"genomics_binding_deepsea_gm12878\",\n",
    "#     model=\"tfti_transformer\",\n",
    "#     hparams_set=\"tfti_transformer_base\",\n",
    "#     hparams=\"\",\n",
    "#     checkpoint_path=\"/data/akmorrow/tfti/t2t_train/6-64-25/model.ckpt-210001\",\n",
    "#     batch_size=batch_size\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsetting shared_embedding_and_softmax_weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:47,731] Unsetting shared_embedding_and_softmax_weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:47,733] Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:47,734] Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:47,736] Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:47,737] Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:47,738] Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:47,739] Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Generated 0 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:47,871] Generated 0 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Generated 1000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:48,342] Generated 1000 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Generated 2000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:48,831] Generated 2000 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Generated 3000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:49,308] Generated 3000 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Generated 4000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:49,804] Generated 4000 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Generated 5000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:50,284] Generated 5000 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Generated 6000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:50,762] Generated 6000 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Generated 7000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 16:24:51,258] Generated 7000 examples.\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = os.path.expanduser(\"/data/epitome/tmp/\")\n",
    "\n",
    "config = tfti_infer.get_config(problem_str, model_str, hparams_set_str, hparams_str, checkpoint_path)\n",
    "problem, model, hparams = tfti_infer.get_problem_model_hparams(config)\n",
    "generator = problem.generator(tmp_dir, is_training=False)\n",
    "generator_list = list(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pseudo_batch(x, n):\n",
    "    \"\"\"Yields the value x n-times.\"\"\"\n",
    "    for _ in range(n):\n",
    "        yield x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Marks for CellType GM12878: [(204, 'GM12878|ATF2|None'), (205, 'GM12878|ATF3|None'), (207, 'GM12878|BCL11A|None'), (410, 'GM12878|BRCA1|None'), (210, 'GM12878|CEBPB|None'), (412, 'GM12878|CHD1|None'), (413, 'GM12878|CHD2|None'), (127, 'GM12878|CTCF|None'), (53, 'GM12878|DNase|None'), (128, 'GM12878|EZH2|None'), (212, 'GM12878|Egr-1|None'), (216, 'GM12878|GABP|None'), (420, 'GM12878|JunD|None'), (421, 'GM12878|Max|None'), (423, 'GM12878|Mxi1|None'), (223, 'GM12878|NRSF|None'), (428, 'GM12878|Nrf1|None'), (229, 'GM12878|Pol2-4H8|None'), (230, 'GM12878|Pol2|None'), (436, 'GM12878|RFX5|None'), (235, 'GM12878|RXRA|None'), (233, 'GM12878|Rad21|None'), (437, 'GM12878|SIN3A|None'), (236, 'GM12878|SIX5|None'), (237, 'GM12878|SP1|None'), (238, 'GM12878|SRF|None'), (240, 'GM12878|TAF1|None'), (442, 'GM12878|TBP|None'), (241, 'GM12878|TCF12|None'), (243, 'GM12878|USF-1|None'), (444, 'GM12878|USF2|None'), (244, 'GM12878|YY1|None'), (447, 'GM12878|Znf143|None'), (725, 'GM12878|c-Myc|None'), (224, 'GM12878|p300|None')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 17:38:27,425] Marks for CellType GM12878: [(204, 'GM12878|ATF2|None'), (205, 'GM12878|ATF3|None'), (207, 'GM12878|BCL11A|None'), (410, 'GM12878|BRCA1|None'), (210, 'GM12878|CEBPB|None'), (412, 'GM12878|CHD1|None'), (413, 'GM12878|CHD2|None'), (127, 'GM12878|CTCF|None'), (53, 'GM12878|DNase|None'), (128, 'GM12878|EZH2|None'), (212, 'GM12878|Egr-1|None'), (216, 'GM12878|GABP|None'), (420, 'GM12878|JunD|None'), (421, 'GM12878|Max|None'), (423, 'GM12878|Mxi1|None'), (223, 'GM12878|NRSF|None'), (428, 'GM12878|Nrf1|None'), (229, 'GM12878|Pol2-4H8|None'), (230, 'GM12878|Pol2|None'), (436, 'GM12878|RFX5|None'), (235, 'GM12878|RXRA|None'), (233, 'GM12878|Rad21|None'), (437, 'GM12878|SIN3A|None'), (236, 'GM12878|SIX5|None'), (237, 'GM12878|SP1|None'), (238, 'GM12878|SRF|None'), (240, 'GM12878|TAF1|None'), (442, 'GM12878|TBP|None'), (241, 'GM12878|TCF12|None'), (243, 'GM12878|USF-1|None'), (444, 'GM12878|USF2|None'), (244, 'GM12878|YY1|None'), (447, 'GM12878|Znf143|None'), (725, 'GM12878|c-Myc|None'), (224, 'GM12878|p300|None')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ATF2', 'ATF3', 'BCL11A', 'BRCA1', 'CEBPB', 'CHD1', 'CHD2', 'CTCF', 'DNase', 'EZH2', 'Egr-1', 'GABP', 'JunD', 'Max', 'Mxi1', 'NRSF', 'Nrf1', 'Pol2-4H8', 'Pol2', 'RFX5', 'RXRA', 'Rad21', 'SIN3A', 'SIX5', 'SP1', 'SRF', 'TAF1', 'TBP', 'TCF12', 'USF-1', 'USF2', 'YY1', 'Znf143', 'c-Myc', 'p300']\n",
      "INFO:tensorflow:Computing average auROC for set ['ATF2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-02 17:38:28,314] Computing average auROC for set ['ATF2']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed validation set in 46.68943524360657 seconds\n",
      "INFO:tensorflow:Computed average auROC: 0.8113998834615973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/akmorrow/anaconda2/envs/python36/lib/python3.6/site-packages/sklearn/metrics/ranking.py:571: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "[2018-05-02 17:39:15,091] Computed average auROC: 0.8113998834615973\n"
     ]
    }
   ],
   "source": [
    "# reload(tfti_infer)\n",
    "cell_type_1 = \"GM12878\"\n",
    "cell_type_2 = \"H1-hESC\"\n",
    "\n",
    "\n",
    "marks = get_tfs(problem, cell_type_1, cell_type_2)\n",
    "marks_str = '\\t'.join(marks)\n",
    "print(marks)\n",
    "\n",
    "# get all combs up to 2. This should take about 10 hours.\n",
    "depth = 2\n",
    "power_set = shapley.power_set(marks, depth=depth)\n",
    "\n",
    "batch_size = 64\n",
    "inputs  = np.array(list(map(lambda x: x['inputs'], generator_list)))\n",
    "targets = np.array(list(map(lambda x: x['targets'], generator_list)))\n",
    "\n",
    "f= open(f\"shapley_values_64_25_gm12878_depth_{depth}.txt\",\"w+\")\n",
    "f.write(f\"permutation\\t{marks_str}\\taverageAuROC\\n\")\n",
    "\n",
    "for set_ in power_set[1:2]:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    tf.logging.info(\"Computing average auROC for set %s\" % set_)\n",
    "    # select marks for this run\n",
    "    selected_marks = [m for m in marks if m in set_]\n",
    "    \n",
    "    keep_mask = tfti_infer.get_keep_mask_for_marks(problem, selected_marks, cell_type_1)\n",
    "    \n",
    "    # instantiate labels and predictions for this set\n",
    "    labels_numpy = np.zeros((len(generator_list), len(marks) ))\n",
    "    predictions_numpy = np.zeros((len(generator_list), len(marks) ))\n",
    "    \n",
    "    for i in range(0, len(generator_list), batch_size):\n",
    "        batch_keep_mask = pseudo_batch(keep_mask, batch_size)\n",
    "        \n",
    "        batch = preprocess_batch_fn(\n",
    "            inputs[i:i+batch_size],\n",
    "            targets[i:i+batch_size],\n",
    "            batch_keep_mask\n",
    "\n",
    "        )\n",
    "        response = inference_fn(batch)\n",
    "        labels_numpy[i:i+batch_size] = response['labels'].reshape((batch_size, len(marks)))\n",
    "        predictions_numpy[i:i+batch_size] = response['predictions'].reshape((batch_size, len(marks)))\n",
    "            \n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(f\"Completed validation set in {elapsed} seconds\")\n",
    "    \n",
    "    roc_aucs = []\n",
    "    for i in range(len(marks)):\n",
    "        # Compute micro-average ROC area for all marks\n",
    "        fpr, tpr, _ = roc_curve(labels_numpy[:,i], predictions_numpy[:,i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_aucs.append(roc_auc)\n",
    "        \n",
    "    roc_auc_str = '\\t'.join(str(x) for x in roc_aucs)\n",
    "    \n",
    "    # filter out nans to compute auc\n",
    "    roc_aucs = np.array(roc_aucs)\n",
    "    average_roc = roc_aucs[np.logical_not(np.isnan(roc_aucs))].mean()\n",
    "    tf.logging.info(\"Computed average auROC: %s\" % (average_roc))\n",
    "    \n",
    "    # save values\n",
    "    f.write(\"%s\\t%s\\t%s\\n\" % (selected_marks, roc_auc_str, average_roc))\n",
    "    f.flush()\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfs(problem, cell_type_1, cell_type_2):\n",
    "    items = problem.get_overlapping_indices_for_cell_type(cell_type_1, cell_type_2)[1]\n",
    "    return list(map(lambda x: x[1].split('|')[1], items))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.array(list(map(lambda x: x['targets'], generator_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_aucs = np.array(roc_aucs)\n",
    "x= np.array2string(roc_aucs, precision=3, separator='\\t')[1:][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.969840356434741\\t0.9626767764465282\\t0.717659128377894\\t0.755714659572096\\t0.6608722615979381\\t0.33207228614307155\\t0.852525631407852\\t0.818784392196098\\t0.8801328597530242\\t0.9615089554108217\\t0.9906578947368421\\t0.7052520482272548\\t0.965710675078621\\t0.8049897221819763\\t0.9446392785571142\\t0.7090840840840841\\t0.8289036776605838\\tnan\\t0.9050471292380475\\t0.9793772098332358\\t0.5058674108260885\\t0.770267322413041\\t0.5922763141348089\\t0.5258956416960685\\t0.9567371891170089\\t0.9645382028859296\\t0.7734605632169366\\tnan\\t0.7909421363294514\\t0.8953428747236719\\tnan\\t0.8499699359565959\\t0.8566993710691824\\t0.9452613502200279\\t0.7920889312444795'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8113998834615973"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATF2/tATF3/tBCL11A/tBRCA1/tCEBPB/tCHD1/tCHD2/tCTCF/tDNase/tEZH2/tEgr-1/tGABP/tJunD/tMax/tMxi1/tNRSF/tNrf1/tPol2-4H8/tPol2/tRFX5/tRXRA/tRad21/tSIN3A/tSIX5/tSP1/tSRF/tTAF1/tTBP/tTCF12/tUSF-1/tUSF2/tYY1/tZnf143/tc-Myc/tp300'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
