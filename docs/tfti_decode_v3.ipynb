{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dummy checkpoint\n",
    "\n",
    "```\n",
    "PROBLEM=genomics_binding_deepsea_gm12878\n",
    "MODEL=tfti_transformer\n",
    "HPARAMS_SET=tfti_transformer_debug\n",
    "HPARAMS=''\n",
    "\n",
    "USR_DIR=./tfti\n",
    "DATA_DIR=./tfti/dev\n",
    "TRAIN_DIR=$HOME/t2t_train/$PROBLEM/$MODEL-$HPARAMS_SET-$HPARAMS\n",
    "\n",
    "mkdir -p $DATA_DIR $TRAIN_DIR\n",
    "\n",
    "# Train\n",
    "t2t-trainer \\\n",
    "  --t2t_usr_dir=$USR_DIR \\\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=$MODEL \\\n",
    "  --hparams_set=$HPARAMS_SET \\\n",
    "  --output_dir=$TRAIN_DIR \\\n",
    "  --hparams=$HPARAMS\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexyku/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import collections\n",
    "\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor import problems\n",
    "from tensor2tensor.layers import common_layers\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import t2t_model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.utils import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../tfti\")\n",
    "import tfti\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.WARN)\n",
    "# tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mode = tf.estimator.ModeKeys.EVAL  # set dropout to 0.0\n",
    "\n",
    "data_dir  = \"unused\"  # will error out if `None` or empty-string\n",
    "# to get the latest checkpoint in a directory: `tf.train.latest_checkpoint(\"path/to/ckpt_dir\")`\n",
    "# otherwise, specify the checkpoint file explicitly\n",
    "ckpt_path = (\"/Users/alexyku/t2t_train/genomics_binding_deepsea_gm12878/\"\n",
    "             \"tfti_transformer-tfti_transformer_debug-/model.ckpt-1\")\n",
    "\n",
    "problem_name = \"genomics_binding_deepsea_gm12878\"\n",
    "model_name   = \"tfti_transformer\"\n",
    "hparams_set  = \"tfti_transformer_debug\"\n",
    "hparams_overrides_str = \"\"\n",
    "\n",
    "hparams  = trainer_lib.create_hparams(hparams_set, hparams_overrides_str, data_dir, problem_name)\n",
    "model    = registry.model(model_name)(hparams, mode)\n",
    "problem  = registry.problem(problem_name)\n",
    "encoders = problem.get_feature_encoders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# dummy data to infer\n",
    "inputs_ph = tf.placeholder(tf.string, shape=[])\n",
    "targets_ph = tf.placeholder(tf.int64, shape=[919])\n",
    "keep_mask_ph = tf.placeholder(tf.bool, shape=[919])\n",
    "\n",
    "# Preprocess examples.\n",
    "features = {\n",
    "    \"inputs\": inputs_ph,\n",
    "    \"targets\": targets_ph,\n",
    "    \"latent_keep_mask\": keep_mask_ph\n",
    "}\n",
    "encoded_inputs = problem.preprocess_example(features, mode, hparams)\n",
    "encoded_inputs[\"target_space_id\"] = 0  # generic id space\n",
    "\n",
    "# Artificial batch dimension because the model demands it.\n",
    "for k in [\"inputs\", \"targets\", \"latents\", \"metrics_weights\"]:\n",
    "    encoded_inputs[k] =  tf.expand_dims(encoded_inputs[k], axis=0)\n",
    "\n",
    "# Features to logits.\n",
    "with tf.variable_scope(model_name):\n",
    "    logits, _ = model.model_fn(encoded_inputs)\n",
    "    preds = tf.nn.sigmoid(logits)\n",
    "\n",
    "# Add an op to initialize the variables.\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "variables_to_restore = [\n",
    "    v for v in tf.contrib.slim.get_variables_to_restore()\n",
    "    if \"global_step\" not in v.name\n",
    "]\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "# Initialize and restore variables.\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init_op)\n",
    "saver.restore(sess, ckpt_path)\n",
    "\n",
    "def infer(inputs, targets, keep_mask):\n",
    "    \"\"\"Runs inference on a single example.\"\"\"\n",
    "    fetch = {\n",
    "        \"predictions\": tf.reshape(preds, shape=[-1]),\n",
    "        \"targets\": tf.reshape(features[\"targets\"], shape=[-1]),\n",
    "    }\n",
    "    return sess.run(fetch, feed_dict={\n",
    "        inputs_ph: inputs,\n",
    "        targets_ph: targets,\n",
    "        keep_mask_ph: keep_mask,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [0.3146048 0.3146048 0.3146048 0.3146048 0.3146048 0.3146048 0.3146048\n",
      " 0.3146048 0.3146048 0.3146048 0.3146048 0.3146048 0.3146048 0.3146048\n",
      " 0.3146048 0.3146048 0.3146048 0.3146048 0.3146048 0.3146048 0.3146048\n",
      " 0.3146048 0.3146048 0.3146048 0.3146048 0.3146048 0.3146048 0.3146048\n",
      " 0.3146048 0.3146048 0.3146048 0.3146048 0.3146048 0.3146048 0.3146048]\n",
      "targets: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "inputs = \"NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTTGAATTTGAATTTGAATTTGAATTTGAATTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTTGAATTTGAATTTGAAATTTGAAATTTGAATTTGAATTTGAATTTGAATTTGAATTTTAATTTTAATTTTAATTTTAATTTTAATTTTAATTTGAATTTTGAATTTGAATTTGAATTTGATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTTGAATTTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTGAATTTTGAATTTGAATTTGAATTTGAATTTGTCTCCGATTTGTACTTCCTTTCTTTCTTTCCCGTGCATTGCACCACAATGCGCTGTTCTTGGTACACGATTATTCAAAGTGCGCTACACCATAATCTACTGTTCTTTGTCTCCGCTGTGTTCCCGTGCGCTG\"\n",
    "targets = \"0000000000000000000000000000000000000000000000000000000000001000000100000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000010001101000000000000000000000010000000000000000000000000000000000000000000000000000000\"\n",
    "targets = np.array(list(map(int, targets)))\n",
    "keep_mask = np.zeros(targets.shape).astype(bool)\n",
    "\n",
    "fetch = infer(inputs, targets, keep_mask)\n",
    "print(f\"predictions: {fetch['predictions']}\")\n",
    "print(f\"targets: {fetch['targets']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
